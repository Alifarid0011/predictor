{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# كتاب خانه هاي استفاده شده :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from os import path, makedirs, walk\n",
    "from joblib import dump, load\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    print(\"Model trained in {:2f} seconds\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(clf, features, target):\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    print(\"Made Predictions in {:2f} seconds\".format(end-start))\n",
    "\n",
    "    acc = sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "    return f1_score(target, y_pred, average='micro'), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(clf, X_train, y_train, X_test, y_test):\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(\"Training Info:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"F1 Score:{}\".format(f1))\n",
    "    print(\"Accuracy:{}\".format(acc))\n",
    "\n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"Test Metrics:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"F1 Score:{}\".format(f1))\n",
    "    print(\"Accuracy:{}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_clean_sheet(src):\n",
    "    arr = []\n",
    "    n_rows = src.shape[0]\n",
    "\n",
    "    for data in range(n_rows):\n",
    "\n",
    "        #[HTHG, HTAG]\n",
    "        values = src.iloc[data].values\n",
    "        cs = [0, 0]\n",
    "\n",
    "        if values[0] == 0:\n",
    "            cs[1] = 1\n",
    "\n",
    "        if values[1] == 0:\n",
    "            cs[0] = 1\n",
    "\n",
    "        arr.append(cs)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data_folder = 'english'\n",
    "es_data_folder = 'spanish'\n",
    "fr_data_folder = 'french'\n",
    "ge_data_folder = 'german'\n",
    "it_data_folder = 'italian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folders = [es_data_folder]\n",
    "data_folders = [en_data_folder, es_data_folder,\n",
    "                fr_data_folder, ge_data_folder, it_data_folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_range = (9, 18)\n",
    "\n",
    "data_files = []\n",
    "for data_folder in data_folders:\n",
    "    for season in range(season_range[0], season_range[1] + 1):\n",
    "        data_files.append(\n",
    "            'data/{}/data/season-{:02d}{:02d}_csv.csv'.format(data_folder, season, season + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "for data_file in data_files:\n",
    "    if path.exists(data_file):\n",
    "        data_frames.append(pd.read_csv(data_file))\n",
    "        \n",
    " data = pd.concat(data_frames).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## home_encoded = كد نسبت داده شده به تيمي كه در خانه خود بازي ميكند \n",
    "## away_encoded=كد نسبت داده شده به تيمي كه در خانه حريف بازي ميكند \n",
    "# HTHG= تعداد گل نيمه اول تيمي كه در خانه بازي ميكند\n",
    "# HTAG=تعداد گل نيمه اول تيمي كه در خانه حريف بازي ميكند\n",
    "# HS= تعداد شوت هاي تيم ميزبان\n",
    "# AS= تعداد شوت هاي تيم ميهمان\n",
    "# HST= شوت در چهارچوب تيم ميزبان\n",
    "# AST=شوت در چهارچوب تيم ميهمان \n",
    "# HR=كارت قرمز ميزبان\n",
    "# AR=كارت قرمز ميهمان \n",
    "# FTR = نتيجه كلي"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_filter = ['home_encoded', 'away_encoded', 'HTHG', 'HTAG', 'HS',\n",
    "                'AS', 'HST', 'AST', 'HR', 'AR']\n",
    "\n",
    "output_filter = ['FTR']\n",
    "\n",
    "cols_to_consider = input_filter + output_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "home_encoded = encoder.fit_transform(data['HomeTeam'])\n",
    "home_encoded_mapping = dict(\n",
    "    zip(encoder.classes_, encoder.transform(encoder.classes_).tolist()))\n",
    "data['home_encoded'] = home_encoded\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "away_encoded = encoder.fit_transform(data['AwayTeam'])\n",
    "away_encoded_mapping = dict(\n",
    "    zip(encoder.classes_, encoder.transform(encoder.classes_).tolist()))\n",
    "data['away_encoded'] = away_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       home_encoded  away_encoded  HTHG  HTAG    HS    AS  HST  AST   HR   AR  \\\n",
      "10585            16            95   NaN   NaN   NaN   NaN  NaN  NaN  NaN  NaN   \n",
      "15254            35           129   NaN   NaN   NaN   NaN  NaN  NaN  NaN  NaN   \n",
      "16757           132           121   NaN   NaN  13.0  15.0  3.0  5.0  0.0  0.0   \n",
      "\n",
      "      FTR  \n",
      "10585   A  \n",
      "15254   A  \n",
      "16757   A  \n"
     ]
    }
   ],
   "source": [
    "data = data[cols_to_consider]\n",
    "\n",
    "print(data[data.isna().any(axis=1)])\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[input_filter]\n",
    "Y = data['FTR']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "svc_classifier = SVC(random_state=100, kernel='rbf')\n",
    "lr_classifier = LogisticRegression(multi_class='ovr', max_iter=500)\n",
    "nbClassifier = GaussianNB()\n",
    "dtClassifier = DecisionTreeClassifier()\n",
    "rfClassifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression one vs All Classifier\n",
      "--------------------\n",
      "Model trained in 1.008652 seconds\n",
      "Made Predictions in 0.003000 seconds\n",
      "Training Info:\n",
      "--------------------\n",
      "F1 Score:0.6577861687993847\n",
      "Accuracy:0.6577861687993847\n",
      "Made Predictions in 0.003000 seconds\n",
      "Test Metrics:\n",
      "--------------------\n",
      "F1 Score:0.6708612975391499\n",
      "Accuracy:0.6708612975391499\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Logistic Regression one vs All Classifier\")\n",
    "print(\"-\" * 20)\n",
    "model(lr_classifier, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussain Naive Bayes Classifier\n",
      "--------------------\n",
      "Model trained in 0.019043 seconds\n",
      "Made Predictions in 0.010999 seconds\n",
      "Training Info:\n",
      "--------------------\n",
      "F1 Score:0.6262499125935249\n",
      "Accuracy:0.6262499125935249\n",
      "Made Predictions in 0.001960 seconds\n",
      "Test Metrics:\n",
      "--------------------\n",
      "F1 Score:0.6451342281879194\n",
      "Accuracy:0.6451342281879194\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Gaussain Naive Bayes Classifier\")\n",
    "print(\"-\" * 20)\n",
    "model(nbClassifier, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier\n",
      "--------------------\n",
      "Model trained in 1.361227 seconds\n",
      "Made Predictions in 0.251048 seconds\n",
      "Training Info:\n",
      "--------------------\n",
      "F1 Score:0.9998601496398853\n",
      "Accuracy:0.9998601496398853\n",
      "Made Predictions in 0.075000 seconds\n",
      "Test Metrics:\n",
      "--------------------\n",
      "F1 Score:0.6552013422818792\n",
      "Accuracy:0.6552013422818792\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Random Forest Classifier\")\n",
    "print(\"-\" * 20)\n",
    "model(rfClassifier, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to export the model(s) (y / n) ? y\n",
      "Model(s) exported successfully to exportedModels/\n"
     ]
    }
   ],
   "source": [
    "shouldExport = input('Do you want to export the model(s) (y / n) ? ')\n",
    "if shouldExport.strip().lower() == 'y':\n",
    "    exportedModelsPath = 'exportedModels'\n",
    "\n",
    "    makedirs(exportedModelsPath, exist_ok=True)\n",
    "\n",
    "    dump(lr_classifier, f'{exportedModelsPath}/lr_classifier.model')\n",
    "    dump(nbClassifier, f'{exportedModelsPath}/nb_classifier.model')\n",
    "    dump(rfClassifier, f'{exportedModelsPath}/rf_classifier.model')\n",
    "\n",
    "    exportMetaData = dict()\n",
    "    exportMetaData['home_teams'] = home_encoded_mapping\n",
    "    exportMetaData['away_teams'] = away_encoded_mapping\n",
    "\n",
    "    exportMetaDataFile = open(f'{exportedModelsPath}/metaData.json', 'w')\n",
    "    json.dump(exportMetaData, exportMetaDataFile)\n",
    "\n",
    "    print(f'Model(s) exported successfully to {exportedModelsPath}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 1.394069 seconds\n",
      "Made Predictions in 0.260047 seconds\n",
      "Training Info:\n",
      "--------------------\n",
      "F1 Score:0.9999300748199427\n",
      "Accuracy:0.9999300748199427\n",
      "Made Predictions in 0.010998 seconds\n",
      "Test Metrics:\n",
      "--------------------\n",
      "F1 Score:0.3333333333333333\n",
      "Accuracy:0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "ytest=['A','H','D'];\n",
    "xtest = pd.DataFrame([[18.0, 164.0, 4.0, 5.0, 12.0,12.0, 4.0, 5.0, 2.0, 2.0],[18.0, 164.0, 4.0, 5.0, 12.0,12.0, 4.0, 5.0, 2.0, 2.0],[18.0, 164.0, 4.0, 5.0, 12.0,12.0, 4.0, 5.0, 2.0, 2.0]],\n",
    "                    columns=['home_encoded', 'away_encoded', 'HTHG', 'HTAG', 'HS',\n",
    "                'AS', 'HST', 'AST', 'HR', 'AR'])\n",
    "model(rfClassifier, X_train, Y_train, xtest, ytest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4 , 0.27, 0.33]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfClassifier.predict_proba([[8, 164, 4, 5, 12,12, 4, 5, 2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84482601, 0.06563271, 0.08954128],\n",
       "       [0.84997353, 0.05909177, 0.0909347 ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_classifier.predict_proba([[8, 164, 4, 5, 12,12, 4, 5, 2, 2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
